{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import glob\n",
    "from pymatreader import read_mat\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, seq_length, is_train, transform=None):\n",
    "        self.transform = transform\n",
    "        self.seqs = []\n",
    "        self.seq_labels = []\n",
    "        self.class_names = os.listdir(root)\n",
    "        self.class_names.sort()\n",
    "        self.numof_classes = len(self.class_names)\n",
    "        self.seq_length = seq_length\n",
    "        self.is_train = is_train\n",
    "\n",
    "        for (i,x) in enumerate(self.class_names):\n",
    "            temp = glob.glob(os.path.join(root, x, '*'))\n",
    "            temp.sort()\n",
    "            self.seq_labels.extend([i]*len(temp))\n",
    "            for t in temp:\n",
    "                df = pd.read_csv(t, header=None)\n",
    "                tensor = preprocess(df)\n",
    "                self.seqs.append(tensor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq = self.seqs[index]\n",
    "        if self.transform is not None:\n",
    "            seq = self.transform(seq, is_train=self.is_train, seq_length=self.seq_length)\n",
    "        return {'seq':seq, 'label':self.seq_labels[index]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "def preprocess(df: pd.DataFrame)->np.ndarray:\n",
    "    mat = df.T.values\n",
    "    mat = standardization(mat, axis=1)\n",
    "\n",
    "    return mat\n",
    "\n",
    "def standardization(a, axis=None, ddof=0):\n",
    "    a_mean = a.mean(axis=axis, keepdims=True)\n",
    "    a_std = a.std(axis=axis, keepdims=True, ddof=ddof)\n",
    "    a_std[np.where(a_std==0)] = 1\n",
    "\n",
    "    return (a - a_mean) / a_std\n",
    "\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    data_noisy = data + noise\n",
    "\n",
    "    return data_noisy.astype(np.float32)\n",
    "\n",
    "def time_shift(data, shift):\n",
    "    data_shifted = np.roll(data, shift)\n",
    "\n",
    "    return data_shifted\n",
    "\n",
    "def transform(array, is_train, seq_length):\n",
    "    if is_train:\n",
    "        _, n = array.shape\n",
    "        s = random.randint(0, n-seq_length)\n",
    "        ts = array[:,s:s+seq_length]\n",
    "        ts = add_noise(ts).astype(np.float32)\n",
    "        if random.randint(0,1):\n",
    "            ts_r = ts[:,::-1].copy()\n",
    "            return ts_r\n",
    "        return ts\n",
    "    else:\n",
    "        ts = array[:,:seq_length].astype(np.float32)\n",
    "        return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "\n",
    "train_datasets = []\n",
    "train_ids = ['subject0', 'subject1', 'subject2', 'subject3']\n",
    "\n",
    "for train_id in train_ids:\n",
    "    train_dir = os.path.join('Motion Decoding Using Biosignals', 'dataset', 'train', train_id)\n",
    "    dataset = SeqDataset(root=train_dir, seq_length=250, is_train=True, transform=transform)\n",
    "    train_datasets.append(dataset)\n",
    "\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "test_dir = os.path.join('Motion Decoding Using Biosignals', 'dataset', 'val', 'subject4')\n",
    "\n",
    "test_dataset = SeqDataset(root=test_dir, seq_length=250, is_train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling conv1d\n",
    "\n",
    "class conv1d(torch.nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(conv1d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(num_channels, 32, kernel_size=7, stride=1, padding=3)\n",
    "        self.conv2 = torch.nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv3 = torch.nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1) \n",
    "        \n",
    "        self.bn1 = torch.nn.BatchNorm1d(32)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.maxpool = torch.nn.MaxPool1d(kernel_size=3, stride=2)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.gap = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.gap(x)\n",
    "        x = x.squeeze(2)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "num_channels = 72 \n",
    "num_classes = 3  \n",
    "\n",
    "model = conv1d(num_channels, num_classes)\n",
    "\n",
    "input_data = torch.randn(32, num_channels, 300)\n",
    "output_data = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 25.52%  Test Loss: 3.325800 \n",
      "\n",
      "Validation Accuracy: 24.48%  Test Loss: 3.922736 \n",
      "\n",
      "Validation Accuracy: 25.31%  Test Loss: 4.737513 \n",
      "\n",
      "Validation Accuracy: 25.52%  Test Loss: 5.853477 \n",
      "\n",
      "Validation Accuracy: 24.48%  Test Loss: 6.195972 \n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      " backside_kickturn       0.35      0.39      0.37       123\n",
      "frontside_kickturn       0.00      0.00      0.00       115\n",
      "           pumping       0.33      0.29      0.31       240\n",
      "\n",
      "          accuracy                           0.24       478\n",
      "         macro avg       0.23      0.23      0.23       478\n",
      "      weighted avg       0.26      0.24      0.25       478\n",
      "\n",
      "Final Acccuracy: 0.24476987447698745\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch, iteration):\n",
    "\n",
    "    model.train()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for sample_batched in train_loader:\n",
    "        data, target = sample_batched['seq'].to(device), sample_batched['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iteration += 1\n",
    "\n",
    "    #    if iteration % log_interval == 0:\n",
    "    #        print('Train Accracy: {3:5.2f}%  train_loss: {2:.6f} \\n'.format(epoch, iteration, loss.item(), 100.*correct/float(len(sample_batched['label']))))\n",
    "            \n",
    "    return iteration\n",
    "\n",
    "def val(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample_batched in test_loader:\n",
    "            data, target = sample_batched['seq'].to(device), sample_batched['label'].to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= float(len(test_loader.dataset))\n",
    "    correct /= float(len(test_loader.dataset))\n",
    "    \n",
    "    print('Validation Accuracy: {0:.2f}%  Test Loss: {1:.6f} \\n'.format(100. * correct, test_loss))\n",
    "\n",
    "    return test_loss, 100. * correct\n",
    "\n",
    "def evaluate(model, device, test_loader):\n",
    "\n",
    "    preds = []\n",
    "    trues = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample_batched in test_loader:\n",
    "            data, target = sample_batched['seq'].to(device), sample_batched['label'].to(device)\n",
    "            output = model(data)\n",
    "            pred = [test_loader.dataset.class_names[i] for i in list(output.max(1)[1].cpu().detach().numpy())]\n",
    "            preds += pred\n",
    "            true = [test_loader.dataset.class_names[i] for i in list(target.cpu().detach().numpy())]\n",
    "            trues += true\n",
    "\n",
    "    labels = test_loader.dataset.class_names\n",
    "\n",
    "    cm = confusion_matrix(trues, preds, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    cr = classification_report(trues, preds, target_names=labels)\n",
    "    print(cr)\n",
    "    correct = 0\n",
    "\n",
    "    for pred, true in zip(preds, trues):\n",
    "        if pred == true:\n",
    "            correct += 1\n",
    "            \n",
    "    df = pd.DataFrame({'pred': preds, 'true': trues})\n",
    "\n",
    "    return correct/len(trues), df\n",
    "\n",
    "def train_evaluate(train_loader, test_loader, log_interval, num_epoches, seq_length, transform=None, num_channels=72, num_classes=3):\n",
    "\n",
    "    model = conv1d(num_channels=num_channels, num_classes=num_classes)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(1, 1+num_epoches):\n",
    "        iteration = train(log_interval, model, device, train_loader, optimizer, epoch, iteration)\n",
    "        if epoch%10==0:\n",
    "            test_loss, test_acc = val(model, device, test_loader)\n",
    "    acc, df = evaluate(model, device, test_loader)\n",
    "\n",
    "    print(f'Final Acccuracy: {acc}')\n",
    "    return model\n",
    "\n",
    "log_interval = 1000\n",
    "num_epoches = 50\n",
    "seq_length = 250\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "model = train_evaluate(train_loader, test_loader, log_interval, num_epoches, seq_length, transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
